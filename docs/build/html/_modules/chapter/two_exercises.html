

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>chapter.two_exercises &mdash; Machine Learning: A Probabilistic Perspective 0.0.1 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 

  
  <script src="../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../index.html" class="icon icon-home"> Machine Learning: A Probabilistic Perspective
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../modules.html">chapter</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Machine Learning: A Probabilistic Perspective</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../index.html">Module code</a> &raquo;</li>
        
      <li>chapter.two_exercises</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for chapter.two_exercises</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">random</span>

<div class="viewcode-block" id="question_1"><a class="viewcode-back" href="../../chapter.html#chapter.two_exercises.question_1">[docs]</a><span class="k">def</span> <span class="nf">question_1</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    p(gender=boy) = 0.5</span>
<span class="sd">    p(gender=girl) = 0.5</span>

<span class="sd">    Possible outcomes of 2 children:</span>
<span class="sd">    boy, girl</span>
<span class="sd">    boy, boy</span>
<span class="sd">    girl, boy</span>
<span class="sd">    girl, girl</span>

<span class="sd">    a) If you know the neighbor has at least one boy, what is the probability the neighbor has a girl?</span>
<span class="sd">    Sample space: (b,g), (b,b), (g,b). 2/3 events have a girl involved, and they all have equal probability so 2/3.</span>

<span class="sd">    b) What is the probability that the other child is a girl if you see that one is a boy?</span>
<span class="sd">    Sample space: (b,g), (b,b). 1/2. The children are independent of each other, so it&#39;s the same as the probability</span>
<span class="sd">    of one child being a girl.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="kc">None</span></div>


<div class="viewcode-block" id="question_2"><a class="viewcode-back" href="../../chapter.html#chapter.two_exercises.question_2">[docs]</a><span class="k">def</span> <span class="nf">question_2</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    There is a blood found at a crime scene that has no innocent explanation. The blood is of a type found in</span>
<span class="sd">    1% of the population.</span>

<span class="sd">    a) Prosecutor&#39;s fallacy: 1% chance that the defendant would have the crime scene blood type if he was innocent,</span>
<span class="sd">    therefore there is a 99% chance that he is guilty.</span>

<span class="sd">    This is not what the evidence states: 1% of the population could have committed the crime because only they have</span>
<span class="sd">    the suspect blood type. The defendant has that blood type, so he is 1/K people who are in consideration for</span>
<span class="sd">    committing the crime, not 99% likely to have committed the crime. 99% of the population is not in consideration</span>
<span class="sd">    for the crime at all, but based on the blood evidence alone we cannot state the likelihood of this single</span>
<span class="sd">    defendent having committed this crime, only that he is in the consideration set.</span>

<span class="sd">    b) Defendant&#39;s fallacy: There are 800K people in the city, 8000 have the blood type in question. There is just</span>
<span class="sd">    1 in 8000 chance that the defendant is guilty and so has no relevance.</span>

<span class="sd">    While it is true that the defendant is just 1 of 8000 city dwellers that have the matching blood type, the blood</span>
<span class="sd">    is relevant. The true culprit must have that blood type, and so it establishes that further evidence must be</span>
<span class="sd">    produced to establish the innocence or guilt of the defendant. This is far from the situation that we can ignore</span>
<span class="sd">    the blood type, the guilty part(ies) must have that match to be considered for the crime.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="kc">None</span></div>

<div class="viewcode-block" id="question_3"><a class="viewcode-back" href="../../chapter.html#chapter.two_exercises.question_3">[docs]</a><span class="k">def</span> <span class="nf">question_3</span><span class="p">():</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Variance of a sum.</span>

<span class="sd">    .. math::</span>
<span class="sd">        cov[X, Y] &amp;= \mathbb{E}[[X - \mathbb{E}[X]][Y - \mathbb{E}[Y]]]\\</span>
<span class="sd">            &amp;= \mathbb{E}[XY - X\mathbb{E}[Y] - Y\mathbb{E}[X] + \mathbb{E}[X]\mathbb{E}[Y]]\\</span>
<span class="sd">            &amp;= \mathbb{E}[XY] - \mathbb{E}[X]\mathbb{E}[Y] - \mathbb{E}[X]\mathbb{E}[Y] + \mathbb{E}[X]\mathbb{E}[Y]\\</span>
<span class="sd">            &amp;= \mathbb{E}[XY] - \mathbb{E}[X]\mathbb{E}[Y]</span>


<span class="sd">    .. math::</span>
<span class="sd">        var[X + Y] &amp;= \mathbb{E}[(X + Y - \mathbb{E}[X+Y])^2]\\</span>
<span class="sd">            &amp;= \mathbb{E}[X^2] + \mathbb{E}[XY] - \mathbb{E}[X\mathbb{E}[X+Y]] + \mathbb{E}[XY] + \mathbb{E}[Y^2] - \mathbb{E}[Y\mathbb{E}[X+Y]] - \mathbb{E}[X\mathbb{E}[X+Y]] - \mathbb{E}[Y\mathbb{E}[X+Y]] + \mathbb{E}[X+Y]^2\\</span>
<span class="sd">            &amp;= \mathbb{E}[X^2] - \mathbb{E}[X]^2 - \mathbb{E}[X]\mathbb{E}[Y] + \mathbb{E}[Y^2] - \mathbb{E}[Y]^2 - \mathbb{E}[X]\mathbb{E}[Y] +2\mathbb{E}[XY] - \mathbb{E}[X]^2 - 2\mathbb{E}[X]\mathbb{E}[Y] - \mathbb{E}[Y]^2 + \mathbb{E}[X+Y]^2\\</span>
<span class="sd">            &amp;= var(X) + var(Y) + 2\mathbb{E}[XY] - 4\mathbb{E}[X]\mathbb{E}[Y] - \mathbb{E}[X]^2 - \mathbb{E}[Y]^2 + \mathbb{E}[X+Y]^2\\</span>
<span class="sd">            &amp;= var(X) + var(Y) + 2cov(X, Y) - 2\mathbb{E}[X]\mathbb{E}[Y] - \mathbb{E}[X]^2 - \mathbb{E}[Y]^2 + \mathbb{E}[X]^2 + 2\mathbb{E}[X]\mathbb{E}[Y] + \mathbb{E}[Y]^2\\</span>
<span class="sd">            &amp;= var(X) + var(Y) + 2cov(X, Y)\\</span>

<span class="sd">    Returns:</span>
<span class="sd">        None.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="kc">None</span></div>

<div class="viewcode-block" id="question_4"><a class="viewcode-back" href="../../chapter.html#chapter.two_exercises.question_4">[docs]</a><span class="k">def</span> <span class="nf">question_4</span><span class="p">():</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Given:</span>

<span class="sd">    .. math::</span>
<span class="sd">        P(T=p|D=p) &amp;= 0.99\\</span>
<span class="sd">        P(T=n|D=n) &amp;= 0.99\\</span>
<span class="sd">        P(D=p) &amp;= 1/10,000</span>


<span class="sd">    This is an application of Bayes Theorem since we want to update the prior probability of having</span>
<span class="sd">    the disease after knowing the test came back positive. So we have:</span>

<span class="sd">    .. math::</span>
<span class="sd">        P(D=p|T=p) &amp;= \frac{P(T=p|D=p) \cdot P(D=p)}{P(T=p)}, &amp;~\textrm{Bayes Thm.}\\</span>
<span class="sd">                   &amp;= \frac{P(T=p|D=p) \cdot P(D=p)}{\Sigma_d P(T=p|D=d)\cdot P(D=d)}, &amp;~\textrm{Law of Total Prob.}\\</span>
<span class="sd">                   &amp;= \frac{P(T=p|D=p) \cdot P(D=p)}{P(T=p|D=p) \cdot P(D=p) + P(T=p|D=n) \cdot P(D=n)}, &amp;~\textrm{Notation}\\</span>
<span class="sd">                   &amp;= \frac{0.99 \cdot 0.0001}{0.99 \cdot 0.0001 + 0.01 \cdot 0.9999}, &amp;~\textrm{Law of Total Prob.}\\</span>
<span class="sd">                   &amp;\approx 0.0098.</span>


<span class="sd">    This means that the good news is the probability of having the disease is still a little less than 1/100. Also,</span>
<span class="sd">    The second application of the Law of Total Probability is actually two applications:</span>

<span class="sd">    .. math::</span>
<span class="sd">        1 &amp;= P(D=p) + P(D=n)\\</span>
<span class="sd">        1 &amp;= P(T=p|D=p) + P(T=p|D=n)</span>


<span class="sd">    Returns:</span>
<span class="sd">        None.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="mf">0.99</span><span class="o">*</span><span class="mf">0.0001</span><span class="o">/</span><span class="p">(</span><span class="mf">0.99</span><span class="o">*</span><span class="mf">0.0001</span><span class="o">+</span><span class="mf">0.01</span><span class="o">*</span><span class="mf">0.9999</span><span class="p">))</span>
    <span class="k">return</span> <span class="kc">None</span></div>


<div class="viewcode-block" id="question_5"><a class="viewcode-back" href="../../chapter.html#chapter.two_exercises.question_5">[docs]</a><span class="k">def</span> <span class="nf">question_5</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">1000000</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">1337</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot; The Monty Hall Problem using Bayes theorem.</span>

<span class="sd">    We&#39;re interested in determining whether switching doors is better than sticking with the original.</span>

<span class="sd">    Let :math:`C \sim Unif(3)` be the random variable representing where the car (prize) is,</span>
<span class="sd">    :math:`F \sim Unif(3)` be the random variable</span>
<span class="sd">    representing the first selection made by the contestant, and :math:`O` be the random variable representing</span>
<span class="sd">    which door is opened after the first selection is made. This variable is deterministic when the first guess does</span>
<span class="sd">    not equal the prize value but has a choice otherwise.</span>

<span class="sd">    .. math::</span>
<span class="sd">        P(F=P|O, P) &amp;= \frac{P(O|F=P) \cdot P(F=P)}{P(O|P=F)},~&amp;\textrm{Bayes Theorem}\\</span>
<span class="sd">                    &amp;= \frac{1/2 \cdot 1/3}{1/2},~&amp;\textrm{Counting}\\</span>
<span class="sd">                    &amp;= 1/3.\\</span>
<span class="sd">        P(F\neq P|O, P) &amp;= \frac{P(O|F\neq P) \cdot P(F\neq P)}{P(O|P\neq F)},~&amp;\textrm{Bayes Theorem}\\</span>
<span class="sd">                        &amp;= \frac{1 \cdot 2/3}{1},~&amp;\textrm{Counting}\\</span>
<span class="sd">                        &amp;= 2/3.</span>

<span class="sd">    So from this we see that our first guess has a 2/3 chance of being wrong given the open door, so switching would</span>
<span class="sd">    give us a 2/3 of being correct in that case. Additionally, by the Law of Total Probability, we could&#39;ve computed</span>
<span class="sd">    the chances of the first guess being correct (1/3) and taking the complement of that.</span>

<span class="sd">    Side-effect:</span>
<span class="sd">        This code runs a simulation of the Monty Hall Problem to compute the probabilities and prints the</span>
<span class="sd">        probability of being right when staying with the original choice or switching to the remaining door.</span>

<span class="sd">    Args:</span>
<span class="sd">         num_samples (int): the number of times to sample the distribution, must be positive.</span>
<span class="sd">         seed (int): the random seed to ensure repeatability.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">random</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span>
    <span class="n">stay</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">switch</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_samples</span><span class="p">):</span>
        <span class="n">prize</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">first</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">prize</span> <span class="o">!=</span> <span class="n">first</span><span class="p">:</span>
            <span class="c1"># Trick: 3 - (0 + 1): 2; 3 - (0 + 2): 1; 3 - (1 + 2): 0.</span>
            <span class="n">open_door</span> <span class="o">=</span> <span class="mi">3</span> <span class="o">-</span> <span class="p">(</span><span class="n">first</span> <span class="o">+</span> <span class="n">prize</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Trick: 1 + 0: 1, 2 + 0: 2; 1 + 1= 2, 1 + 2 = 0; 2 + 1 = 0, 2 + 2 = 1.</span>
            <span class="n">open_door</span> <span class="o">=</span> <span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">prize</span><span class="p">)</span> <span class="o">%</span> <span class="mi">3</span>
        <span class="k">if</span> <span class="n">first</span> <span class="o">==</span> <span class="n">prize</span><span class="p">:</span>
            <span class="n">stay</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="c1"># Trick: 0 + 1 = 2, 0 + 2 = 1, 1 + 0 = 2, 1 + 2 = 0, 2 + 1 = 0 2 + 0 = 1</span>
        <span class="n">second</span> <span class="o">=</span> <span class="mi">3</span> <span class="o">-</span> <span class="p">(</span><span class="n">open_door</span> <span class="o">+</span> <span class="n">first</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">prize</span> <span class="o">==</span> <span class="n">second</span><span class="p">:</span>
            <span class="n">switch</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;Correct stay probability: {stay/num_samples*100:0.3f}%;&quot;</span>
          <span class="n">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Correct switch probability: {switch/num_samples*100:0.3f}%&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="question_6"><a class="viewcode-back" href="../../chapter.html#chapter.two_exercises.question_6">[docs]</a><span class="k">def</span> <span class="nf">question_6</span><span class="p">():</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Want to know if you can compute :math:`P(H|e_1,e_2)` with different givens.</span>

<span class="sd">    Let&#39;s look at what this formula looks like after rearranging.</span>

<span class="sd">    .. math::</span>
<span class="sd">        P(H|e_1,e_2) &amp;= \frac{P(e_1,e_2|H) \cdot P(H)}{P(e_1,e_2)},~&amp;\textrm{Bayes Thm.}\\</span>
<span class="sd">                     &amp;= \frac{P(e_1|H) \cdot P(e_2|H) \cdot P(H)}{P(e_1,e_2)},~&amp;\textrm{Def. of Cond. Ind.}\\</span>
<span class="sd">                     &amp;= \frac{P(e_1|H) \cdot P(e_2|H) \cdot P(H)}{\Sigma_h P(e_1,e_2|H) \cdot P(H)},~&amp;\textrm{Total Probability}\\</span>
<span class="sd">                     &amp;= \frac{P(e_1|H) \cdot P(e_2|H) \cdot P(H)}{\Sigma_h P(e_1|H)\cdot P(e_2|H) \cdot P(H)},~&amp;\textrm{Def. of Cond. Ind.}</span>


<span class="sd">    i.      :math:`P(e_1,e_2), P(H), P(e_1|H), P(e_2|H)`. This is sufficient from the second line above if we assume</span>
<span class="sd">            independence between the :math:`E` variables.</span>
<span class="sd">    ii.     :math:`P(e_1,e_2), P(H), P(e_1,e_2|H)`. This is sufficient from the first line above, a single</span>
<span class="sd">            applications of Bayes Theorem.</span>
<span class="sd">    iii.    :math:`P(e_1|H), P(e_2|H), P(H)`. This is sufficient from the last line, after applying the Law of total</span>
<span class="sd">            probability and Conditional Independence.</span>


<span class="sd">    So (ii) is the answer to part a), when we don&#39;t know anything about the relationship between :math:`E_1` and</span>
<span class="sd">    :math:`E_2`. All sets of givens are sufficient if we know the two variables are conditionally independent.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># What is an example of conditional independence:</span>
    <span class="c1"># https://en.wikipedia.org/wiki/Conditional_independence</span>
    <span class="c1"># P(R|Y) = 4/12, P(B|Y) = 6/12, P(R|Y)*P(B|Y) = 6/36 = 2/12 = P(R,B|Y)</span>
    <span class="c1"># P(!R|Y) = 8/12, P(!B|Y) = 6/12, P(!R|Y)*P(!B|Y) = 8/24 = 4/12 = P(!R,!B|Y)</span>
    <span class="c1"># P(!R|Y) = 8/12, P(B|Y) = 6/12, P(!R|Y)*P(B|Y) = 8/24 = 4/12 = P(!R,B|Y)</span>
    <span class="c1"># P(R|Y) = 4/12, P(!B|Y) = 6/12 P(R|Y)*P(!B|Y) = 6/36 = 2/12 = P(R,!B|Y)</span>
    <span class="c1"># So R \ind B | Y.</span>
    <span class="k">return</span> <span class="kc">None</span></div>


<div class="viewcode-block" id="question_7"><a class="viewcode-back" href="../../chapter.html#chapter.two_exercises.question_7">[docs]</a><span class="k">def</span> <span class="nf">question_7</span><span class="p">():</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot; Pairwise independence does not imply mutual independence.</span>

<span class="sd">    Mutual independence means that :math:`P(X_i|X_S) = P(X_i) \forall S \subseteq \{1,\ldots,n\}\setminus\{i\}`</span>
<span class="sd">    and so the joint distribution of :math:`P(X_{1:n}) = \prod_{i=1}^n P(X_i)`.</span>

<span class="sd">    So it would be enough to show that for 3 variables that are all pairwise independent that they are</span>
<span class="sd">    not mutually independent.</span>

<span class="sd">    Consider a 5x5 grid where one variable :math:`(X_1)` is true only along the bottom 5 squares, another is true only</span>
<span class="sd">    along the right side :math:`(X_2)`, and a third is true only along the main diagonal :math:`(X_3)`. The only overlap</span>
<span class="sd">    any variable has with any other is in the lower right corner square.</span>

<span class="sd">    .. math::</span>
<span class="sd">        P(X_1=T) &amp;= 5/25\\</span>
<span class="sd">        P(X_1=F) &amp;= 20/25\\</span>
<span class="sd">        P(X_1=T,X_2=T) &amp;= 1/25 = 5/25*5/25 = P(X_1=T)P(X_2=T)\\</span>
<span class="sd">        P(X_1=T,X_2=F) &amp;= 4/25 = 5/25*20/25 = P(X_1=T)P(X_2=F)\\</span>
<span class="sd">        P(X_1=F,X_2=T) &amp;= 4/25 = 20/25*5/25 = P(X_1=F)P(X_2=T)\\</span>
<span class="sd">        P(X_1=F,X_2=F) &amp;= 16/25 = 20/25*20/25 = P(X_1=F)P(X_2=F)\\</span>

<span class="sd">    In this way, we see that each pair of variable is conditionally independent. The question is if they are</span>
<span class="sd">    mutually independent. If they were, then :math:`P(X_1,X_2,X_3) = P(X_1)P(X_2)P(X_3)`, but we see for</span>
<span class="sd">    :math:`P(X_1=T,X_2=T,X_3=T) = 1/25` (the lower right corner), but :math:`P(X_1=T)P(X_2=T)P(X_3=T) = 1/125` so</span>
<span class="sd">    we see that being pairwise conditionally independent does not imply mutual independence.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="kc">None</span></div>


<div class="viewcode-block" id="question_8"><a class="viewcode-back" href="../../chapter.html#chapter.two_exercises.question_8">[docs]</a><span class="k">def</span> <span class="nf">question_8</span><span class="p">():</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot; Conditional independence iff joint factorizes.</span>

<span class="sd">    Prove that :math:`p(x,y|z)=g(x,z)h(y,z)~\textrm{iff}~X \perp Y | Z.`</span>

<span class="sd">    First, let :math:`g(x,z) = p(x|z), h(y,z) = p(y|z)` since conditional probabilities</span>
<span class="sd">    are functions of random variables these are permissible definitions of :math:`g, h`.</span>

<span class="sd">    :math:`\textrm{The forward direction:}~X \perp Y | Z \Rightarrow p(x,y|z)=g(x,z)h(y,z).`</span>

<span class="sd">    .. math::</span>
<span class="sd">       p(x,y|z) &amp;= p(x|z)p(y|z),~&amp;\textrm{Def. of Cond. Ind.}\\</span>
<span class="sd">                &amp;= g(x,z)h(y,z),~&amp;\textrm{Defined above.}.</span>

<span class="sd">    Lemma: :math:`p(x|y,z) = p(x|z)~\textrm{if}~X \perp Y | Z.`</span>

<span class="sd">    Proof:</span>

<span class="sd">    .. math::</span>
<span class="sd">        p(x|y,z) &amp;= \frac{p(x,y,z)}{p(y,z)},~&amp;\textrm{Def. of Cond. Prob.}\\</span>
<span class="sd">                 &amp;= \frac{p(x,y|z)p(z)}{p(y|z)p(z)}~&amp;\textrm{Def. of Cond. Prob.}\\</span>
<span class="sd">                 &amp;= \frac{p(x|z)p(y|z)p(z)}{p(y|z)p(z)}~&amp;\textrm{Def. of Cond. Ind.}\\</span>
<span class="sd">                 &amp;= p(x|z).</span>

<span class="sd">    :math:`\textrm{The reverse direction:}~p(x,y|z)=g(x,z)h(y,z) \Rightarrow X \perp Y | Z.`</span>

<span class="sd">    .. math::</span>
<span class="sd">        p(x,y|z) &amp;= \frac{p(x,y,z)}{p(z)},~&amp;\textrm{Def. of Cond. Prob.}\\</span>
<span class="sd">                 &amp;= \frac{p(z)p(y|z)p(x|y,z)}{p(z)},~&amp;\textrm{Chain rule of prob.}\\</span>
<span class="sd">                 &amp;= p(y|z)p(x|z),~&amp;\textrm{By the above lemma, Def. Cond. Ind.}\\</span>
<span class="sd">                 &amp;= g(x,z)h(y,z),~&amp;\textrm{Defined above.}</span>

<span class="sd">    Returns:</span>
<span class="sd">        None.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="kc">None</span></div>


<div class="viewcode-block" id="question_9"><a class="viewcode-back" href="../../chapter.html#chapter.two_exercises.question_9">[docs]</a><span class="k">def</span> <span class="nf">question_9</span><span class="p">():</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot; Conditional independence statements...</span>

<span class="sd">    a) Does :math:`(X \perp W|Z,Y) \wedge (X \perp Y|Z) \Rightarrow (X \perp Y,W|Z)`? Yes.</span>

<span class="sd">        .. math::</span>
<span class="sd">            p(X,Y,W|Z) &amp;= \frac{p(X,Y,W,Z)}{p(Z)},~&amp;\textrm{Def. Cond. Prob.}\\</span>
<span class="sd">                &amp;= \frac{p(X,W|Z,Y)p(Z,Y)}{p(Z)},~&amp;\textrm{Def. Cond. Prob.}\\</span>
<span class="sd">                &amp;= \frac{p(X|Z,Y)p(W|Z,Y)p(Z,Y)}{p(Z)},~&amp;\textrm{First given; Def. Cond. Ind.}\\</span>
<span class="sd">                &amp;= \frac{p(X,Z,Y)p(W|Z,Y)p(Z,Y)}{p(Z,Y)p(Z)},~&amp;\textrm{Def. Cond. Prob.}\\</span>
<span class="sd">                &amp;= \frac{p(X,Y|Z)p(Z)p(W|Z,Y)}{p(Z)},~&amp;\textrm{Def. Cond. Prob.}\\</span>
<span class="sd">                &amp;= p(X|Z)p(Y|Z)p(W|Z,Y),~&amp;\textrm{Second given; Def. Cond. Ind.}\\</span>
<span class="sd">                &amp;= \frac{p(X|Z)p(Y|Z)p(W,Z,Y)}{p(Z,Y)},~&amp;\textrm{Def. Cond. Prob.}\\</span>
<span class="sd">                &amp;= \frac{p(X|Z)p(Y|Z)p(Y,W|Z)p(Z)}{p(Z,Y)},~&amp;\textrm{Def. Cond. Prob.}\\</span>
<span class="sd">                &amp;= \frac{p(X|Z)p(Y,Z)p(Y,W|Z)p(Z)}{p(Z,Y)p(Z)},~&amp;\textrm{Def. Cond. Prob.}\\</span>
<span class="sd">                &amp;= p(X|Z)p(Y,W|Z).</span>

<span class="sd">    b) Does :math:`(X \perp Y|Z) \wedge (X \perp Y|W) \Rightarrow (X \perp Y|Z,W)?` No.</span>

<span class="sd">        If W and Z are describing the same event, then this is a true statement, but in general,</span>
<span class="sd">        it fails. If we construct another discrete example using a 4x4 grid where X is true along</span>
<span class="sd">        the bottom, Y is true along the right side, Z is true along the main diagonal and W is true</span>
<span class="sd">        in the bottom right corner, the top left corner, and along the minor diagonal in the middle two</span>
<span class="sd">        rows (not where Z is true), then we&#39;ll have a contradiction. We get the first two statements as</span>
<span class="sd">        being true, :math:`(X \perp Y |Z) \wedge (X \perp Y|W)`, but we&#39;ll find that :math:`p(X|W,Z) = p(Y|W,Z) = 1/2`</span>
<span class="sd">        while :math:`p(X,Y|W,Z) = 1/2` not 1/4, giving us a contradiction and allowing us to say that the</span>
<span class="sd">        result is not true.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="kc">None</span></div>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">question_5</span><span class="p">()</span>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Steven Loscalzo.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../',
            VERSION:'0.0.1',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  <script type="text/javascript" src="../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>